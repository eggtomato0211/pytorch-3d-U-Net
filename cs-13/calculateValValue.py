import os
import yaml
import h5py
import numpy as np
import torch
from skimage.metrics import peak_signal_noise_ratio

# pytorch-3dunet å†…ã®å„ç¨®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆå¿…è¦ã«å¿œã˜ã¦ãƒ‘ã‚¹ç­‰ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ï¼‰
from pytorch3dunet.unet3d.model import get_model
from pytorch3dunet.unet3d.utils import load_checkpoint
from pytorch3dunet.unet3d.losses import get_loss_criterion
from pytorch3dunet.unet3d.metrics import get_evaluation_metric
from pytorch3dunet.augment.transforms import Normalize

# ======================================
# è¨­å®šãƒ‘ã‚¹ã®æŒ‡å®š
# ======================================
val_dir = r"C:\Users\Owner\mizusaki\3d-holography\app\python\3d-imaging\hdf\val250"
model_checkpoint = r"C:\Users\Owner\mizusaki\pytorch-3dunet\checkpoint\32x32x128\patch=64_stride=48_fm=16_valpatch=128\best_checkpoint.pytorch"
original_config = r"C:\Users\Owner\mizusaki\pytorch-3dunet\cs-13\train-yaml\patch=64_stride=48_fm=16_valpatch=128.yaml"

# ======================================
# YAML è¨­å®šã®èª­ã¿è¾¼ã¿ã¨ãƒ¢ãƒ‡ãƒ«ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# ======================================
with open(original_config, "r") as f:
    config = yaml.safe_load(f)

# ãƒ‡ãƒã‚¤ã‚¹ã®è¨­å®šï¼ˆGPU ãŒã‚ã‚Œã° GPU ã‚’ä½¿ç”¨ï¼‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã—ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
model = get_model(config['model'])
checkpoint = load_checkpoint(model_checkpoint, model)
model = model.to(device)
model.eval()

# å¿…è¦ã«å¿œã˜ã¦ loss, evaluation criterion ã‚’å–å¾—ï¼ˆã“ã“ã§ã¯ PSNR ã‚’ç®—å‡ºã™ã‚‹ãŸã‚ã€skimage ã®é–¢æ•°ã‚’åˆ©ç”¨ï¼‰
loss_criterion = get_loss_criterion(config)
eval_criterion = get_evaluation_metric(config)  # â€»è¨­å®šã«ã‚ˆã£ã¦ã¯ PSNR ãªã©ã®é–¢æ•°ãŒè¿”ã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™

# ======================================
# Normalize ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆ
# ======================================
normalize_transform = Normalize()

# ======================================
# HDF5 ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰é–¢æ•°
# ======================================
def load_hdf5_data(file_path):
    with h5py.File(file_path, 'r') as f:
        print(f"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±: {list(f.keys())}")
        # å„ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ã‚­ãƒ¼ã¯ 'raw' ã¨ 'label' ã¨ä»®å®š
        label_data = f['label'][:]
        raw_data = f['raw'][:]
    
    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«ã‚‚ label ã«ã‚‚æ­£è¦åŒ–ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜å‰å‡¦ç†ã‚’é©ç”¨ï¼‰
    raw_data = normalize_transform(raw_data)
    label_data = normalize_transform(label_data)
    return label_data, raw_data

# ======================================
# validation ç”¨é–¢æ•°ï¼ˆtrainer.validate() ã®æµã‚Œã‚’æ¨¡ã—ã¦å®Ÿè£…ï¼‰
# ======================================
def validate_model(model, file_list, device):
    # è©•ä¾¡ã‚¹ã‚³ã‚¢ã‚’è“„ç©ã™ã‚‹ãƒªã‚¹ãƒˆ
    val_scores = []
    # ã“ã“ã§ã¯ loss ã®è¨ˆç®—ã‚‚å¯èƒ½ã§ã™ãŒã€ä¾‹ã§ã¯ PSNR ã®ã¿ã‚’è¨ˆç®—ã—ã¦ã„ã¾ã™
    
    # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã§ no_grad() ã§å®Ÿè¡Œ
    model.eval()
    with torch.no_grad():
        for i, file_path in enumerate(file_list):
            print(f"ğŸ” Validation iteration {i}: {os.path.basename(file_path)}")
            
            # HDF5 ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            label_data, raw_data = load_hdf5_data(file_path)
            
            # å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«ã¸ã®å¤‰æ›
            # â€»ã“ã“ã§ã¯ raw_data ãŒ 3æ¬¡å…ƒ (D, H, W) ã®å ´åˆã€ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒã¨ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ ã—ã¦ (1, 1, D, H, W) ã¨ã™ã‚‹ä¾‹ã§ã™
            input_tensor = torch.tensor(raw_data, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)
            
            # ---------------------------
            # æ¨è«–ï¼ˆforward passï¼‰
            # ---------------------------
            output_tensor = model(input_tensor)
            
            # â€»å¿…è¦ã«å¿œã˜ã¦ loss ã®è¨ˆç®—ã‚‚å¯èƒ½
            # loss = loss_criterion(output_tensor, target_tensor)
            
            # å‡ºåŠ›ãƒ†ãƒ³ã‚½ãƒ«ã‚’ numpy é…åˆ—ã«å¤‰æ›ï¼ˆãƒãƒƒãƒæ¬¡å…ƒã€ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒã‚’é™¤å»ï¼‰
            output = output_tensor.squeeze(0).squeeze(0).cpu().numpy()

            print(f"Output min/max: {output.min()} / {output.max()}")
            
            # â€»å ´åˆã«ã‚ˆã£ã¦ã¯ã€å‡ºåŠ›ã«å¾Œå‡¦ç†ï¼ˆä¾‹ï¼šå†åº¦æ­£è¦åŒ–ï¼‰ã‚’æ–½ã™
            output = normalize_transform(output)

            print(f"Output min/max: {output.min()} / {output.max()}")
            
            # ---------------------------
            # PSNR ã®è¨ˆç®—
            # ---------------------------
            psnr_value = peak_signal_noise_ratio(
                label_data, output,
                data_range=np.max(label_data) - np.min(label_data)
            )
            print(f"ğŸ“Š PSNR: {psnr_value}")
            val_scores.append(psnr_value)
            
            # 100ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¯ã«ç”»åƒãªã©ã®ãƒ­ã‚°å‡ºåŠ›ã‚’è¡Œã†ï¼ˆå¿…è¦ã«å¿œã˜ã¦å®Ÿè£…ï¼‰
            if i % 100 == 0:
                # ä¾‹: ãƒ­ã‚°ç”¨ã®ç”»åƒã‚’ä¿å­˜ãƒ»TensorBoard ã«å‡ºåŠ›ãªã©
                pass
            
            # â€»å¿…è¦ã§ã‚ã‚Œã°ã€validation ãƒ«ãƒ¼ãƒ—ã®é€”ä¸­ã§ break ã™ã‚‹æ¡ä»¶ã‚‚è¿½åŠ å¯èƒ½
            # if some_condition:
            #     break
    
    # è“„ç©ã—ãŸå„ãƒãƒƒãƒã® PSNR ã®å¹³å‡å€¤ã‚’è¿”ã™
    avg_score = np.mean(val_scores)
    return avg_score

# ======================================
# validation ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®å–å¾—(_predictions.h5 ã¯æ’é™¤)
# ======================================
h5_files = [os.path.join(val_dir, f) for f in os.listdir(val_dir) if f.endswith('.h5') and not f.endswith('_predictions.h5')]

print(f"ğŸ“‚ Validation ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(h5_files)}"
      f"\nğŸ“ Validation ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ: {h5_files}")

# ======================================
# validation ã®å®Ÿè¡Œ
# ======================================
avg_psnr = validate_model(model, h5_files, device)

print("\n==============================")
print(f"ğŸ“Š `best_checkpoint.pytorch` ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ™‚ã® å¹³å‡ PSNR: {avg_psnr}")
print(f"ğŸ“Œ `best_eval_score`: {checkpoint.get('best_eval_score', 'æœªå®šç¾©')}")
print("==============================")

# ======================================
# ä¸€è‡´ãƒã‚§ãƒƒã‚¯
# ======================================
if 'best_eval_score' in checkpoint and np.isclose(avg_psnr, checkpoint['best_eval_score'], atol=1e-5):
    print("âœ… `best_checkpoint.pytorch` ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã¯ `best_eval_score` ã¨å®Œå…¨ã«ä¸€è‡´ã—ã¾ã—ãŸï¼")
else:
    print("âŒ `best_checkpoint.pytorch` ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã¯ `best_eval_score` ã¨ä¸€è‡´ã—ã¾ã›ã‚“ï¼ è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
